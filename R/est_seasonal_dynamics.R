#' Estimate Seasonal Dynamics for Cholera and Precipitation Using Fourier Series
#'
#' This function retrieves historical precipitation data, processes cholera case data, and fits seasonal dynamics models using a double Fourier series. The results are saved to a CSV file, including parameter estimates, fitted values, and processed data.
#'
#' @param PATHS A list containing paths where raw and processed data are stored. Typically generated by the `get_paths()` function and should include:
#' \itemize{
#'   \item \strong{DATA_CLIMATE}: Path to the directory where climate data is stored.
#'   \item \strong{DATA_SHAPEFILES}: Path to the directory containing country shapefiles.
#'   \item \strong{DATA_WHO_WEEKLY}: Path to the directory containing cholera data.
#'   \item \strong{MODEL_INPUT}: Path to the directory where model input files will be saved.
#' }
#' @param date_start A date in YYYY-MM-DD format indicating the start date of the precipitation data (1970-01-01 is earliest)
#' @param date_stop A date in YYYY-MM-DD format indicating the stop date of the precipitation date
#' @param min_obs The minimum number of observations required to fit the fourier series to cholera case data (default is 30)
#' @param clustering_method The name of the clustering method to use when grouping countries by seasonality (i.e. "kmeans", "hierarchical", "ward.D2", "knn")
#' @param k The number of clusters to group countries by seasonality
#'
#' @return The function saves the parameter estimates, fitted values, and processed data to a CSV file.
#'
#' @importFrom dplyr mutate group_by summarize bind_rows
#' @importFrom tidyr spread
#' @importFrom lubridate week year
#' @importFrom sf st_read st_coordinates
#' @importFrom utils write.csv read.csv
#' @importFrom glue glue
#' @importFrom ggplot2 ggplot geom_sf labs theme_minimal
#' @importFrom minpack.lm nlsLM
#' @export

est_seasonal_dynamics <- function(PATHS,
                                  date_start,
                                  date_stop,
                                  min_obs = 30,
                                  clustering_method,
                                  k) {

     requireNamespace('dplyr')
     requireNamespace('minpack.lm')
     requireNamespace('FNN')
     requireNamespace('sf')

     # Load necessary country data
     iso_codes <- MOSAIC::iso_codes_mosaic

     # Load cholera cases data
     cholera_data <- utils::read.csv(file.path(PATHS$DATA_WHO_WEEKLY, "cholera_country_weekly_processed.csv"), stringsAsFactors = FALSE)

     # Filter cholera_data to include only observations within the specified date range
     tmp <- cholera_data[cholera_data$date_start >= date_start & cholera_data$date_stop < date_stop,]

     # Count the number of observations per iso_code within the date range
     n_obs <- table(tmp$iso_code)

     # Define iso_codes_with_data as those with at least min_obs observations.
     # Countries with fewer observations (or none) will be treated as having insufficient data.
     iso_codes_with_data <- names(n_obs[n_obs >= min_obs])

     # Filter cholera_data to include only countries with sufficient data.
     cholera_data <- cholera_data[cholera_data$iso_code %in% iso_codes_with_data,]

     # Define iso_codes_no_data as the set of countries that are missing or have insufficient observations.
     iso_codes_no_data <- setdiff(iso_codes, iso_codes_with_data)

     ################################################################################
     # Model seasonal dynamics of cases and precipitation using Fourier series
     ################################################################################

     normalize_if_needed <- function(x, verbose = FALSE) {

          normalized_x <- tryCatch({

               check_affine_normalization(x, verbose = verbose)
               x

          }, error = function(e) {

               message("Normalization check failed: ", e$message, "\nApplying affine normalization.")
               calc_affine_normalization(x)

          })

          return(normalized_x)
     }

     all_precip_data <- list()
     all_fitted_values <- list()
     all_param_values <- list()

     for (country_iso_code in iso_codes) {

          message(glue::glue("Processing country: {country_iso_code}"))

          country_name <- MOSAIC::convert_iso_to_country(country_iso_code)

          # Load climate data for the country
          precip_file <- file.path(PATHS$DATA_RAW, "climate", glue::glue("climate_data_MRI_AGCM3_2_S_precipitation_sum_1970-01-01_2030-12-31_{country_iso_code}.parquet"))

          # Check if the precipitation file exists
          if (file.exists(precip_file)) {
               message(glue::glue("Loading precipitation data from file for {country_iso_code}"))
               precip_data <- arrow::read_parquet(file = precip_file)
          } else {
               stop(glue::glue("Precipitation data not found for {country_iso_code}."))
          }

          precip_data <- precip_data[precip_data$date >= date_start & precip_data$date < date_stop,]

          # Aggregate weekly precipitation data
          precip_data <- precip_data %>%
               mutate(week = lubridate::week(date), year = lubridate::year(date)) %>%
               group_by(year, week) %>%
               summarize(weekly_precipitation_sum = sum(value, na.rm = TRUE), .groups = 'drop')

          # Merge with cholera data by week and ISO code
          precip_data$iso_code <- country_iso_code
          precip_data <- merge(precip_data, cholera_data, by = c("year", "week", "iso_code"), all.x = TRUE)

          # Create a sequence of weeks for the fitted curve
          week_seq <- 1:52

          # Scale the precipitation and cholera data so that scaled variable is > -1 with mean = 0
          precip_data$precip_scaled <- calc_affine_normalization(precip_data$weekly_precipitation_sum)
          precip_data$cases_scaled <- calc_affine_normalization(precip_data$cases)

          message("Fitting fourier series to precip data")
          fit_fourier_precip <- minpack.lm::nlsLM(
               precip_scaled ~ MOSAIC::fourier_series_double(week, a1, b1, a2, b2, p = 52, beta0 = 0),
               data = precip_data,
               start = list(a1 = 1, b1 = 1, a2 = 0.5, b2 = 0.5)
          )

          # Extract coefficients and standard errors
          coefs_precip <- coef(fit_fourier_precip)
          se_precip <- sqrt(diag(vcov(fit_fourier_precip)))

          param_values_precip <- data.frame(
               country_name = country_name,
               country_iso_code = country_iso_code,
               response = "precipitation",
               parameter = names(coefs_precip),
               mean = coefs_precip,
               se = se_precip,
               ci_lo = coefs_precip - 1.96 * se_precip,
               ci_hi = coefs_precip + 1.96 * se_precip
          )

          # Use MOSAIC::fourier_series_double to calculate fitted values for precipitation
          fitted_values_precip <- MOSAIC::fourier_series_double(week_seq, coefs_precip["a1"], coefs_precip["b1"], coefs_precip["a2"], coefs_precip["b2"], p = 52, beta0 = 0)
          fitted_values_precip <- normalize_if_needed(fitted_values_precip)


          # Fit the Fourier series model to cholera cases if data is available
          n_obs <- sum(!is.na(precip_data$cases))

          if (country_iso_code %in% iso_codes_with_data && n_obs >= min_obs) {

               message(glue::glue("Case data present and >= {min_obs}: fitting fourier series to case data"))

               fit_fourier_cases <- minpack.lm::nlsLM(
                    cases_scaled ~ MOSAIC::fourier_series_double(week, a1, b1, a2, b2, p = 52, beta0 = 0),
                    data = precip_data,
                    start = list(
                         a1 = as.vector(coefs_precip["a1"]),
                         b1 = as.vector(coefs_precip["b1"]),
                         a2 = as.vector(coefs_precip["a2"]),
                         b2 = as.vector(coefs_precip["b2"])
                    )
               )

               coefs_cases <- coef(fit_fourier_cases)
               se_cases <- sqrt(diag(vcov(fit_fourier_cases)))

               param_values_cases <- data.frame(
                    country_name = country_name,
                    country_iso_code = country_iso_code,
                    response = "cases",
                    parameter = names(coefs_cases),
                    mean = coefs_cases,
                    se = se_cases,
                    ci_lo = coefs_cases - 1.96 * se_cases,
                    ci_hi = coefs_cases + 1.96 * se_cases
               )

               # Use MOSAIC::fourier_series_double to calculate fitted values for cholera cases
               fitted_values_cases <- MOSAIC::fourier_series_double(week_seq, coefs_cases["a1"], coefs_cases["b1"], coefs_cases["a2"], coefs_cases["b2"], p = 52, beta0 = 0)
               fitted_values_cases <- normalize_if_needed(fitted_values_cases)

          } else {

               message("No case data present")

               fitted_values_cases <- rep(NA, length(week_seq))

               param_values_cases <- data.frame(
                    country_name = country_name,
                    country_iso_code = country_iso_code,
                    response = "cases",
                    parameter = names(coefs_precip),
                    mean = NA,
                    se = NA,
                    ci_lo = NA,
                    ci_hi = NA
               )
          }

          # Store fitted values
          fitted_values <- data.frame(
               week = week_seq,
               iso_code = country_iso_code,
               fitted_values_fourier_precip = fitted_values_precip,
               fitted_values_fourier_cases = fitted_values_cases
          )

          # Store results for each country
          precip_data$Country <- country_name
          fitted_values$Country <- country_name

          param_values <- rbind(param_values_precip, param_values_cases)

          all_precip_data[[country_iso_code]] <- precip_data
          all_fitted_values[[country_iso_code]] <- fitted_values
          all_param_values[[country_iso_code]] <- param_values

     }

     # Combine all results into a single dataframe
     combined_precip_data <- do.call(rbind, all_precip_data)
     combined_fitted_values <- do.call(rbind, all_fitted_values)
     combined_param_values <- do.call(rbind, all_param_values)

     combined_param_values <- combined_param_values[!(combined_param_values$parameter %in% c("beta0", "p")),]
     row.names(combined_param_values) <- NULL


     # Final check for correct affine normalization for fitted fourier function output
     message("Checking for proper scaling of fourier function values fitted to precip data:")
     check_affine_normalization(combined_fitted_values$fitted_values_fourier_precip, verbose = TRUE)

     message("Checking for proper scaling of fourier function values fitted to case data:")
     check_affine_normalization(combined_fitted_values$fitted_values_fourier_cases, verbose = TRUE)




     ################################################################################

     # Check within cluster first, if not neighbors with data then get nearest neighbor
     # with highest precip correlation

     ################################################################################

     message('Estimating culstering of countries based on seasonal rainfall patterns
             and inferring seasonal transmission dynamics based on the clustering...')

     # Step 1: Perform hierarchical clustering with k = 4

     # Prepare data for clustering
     precip_fitted_df <- combined_fitted_values %>%
          dplyr::filter(!is.na(fitted_values_fourier_precip)) %>%
          dplyr::select(iso_code, week, fitted_values_fourier_precip) %>%
          tidyr::spread(key = week, value = fitted_values_fourier_precip)  # Reshape data

     # Remove rows with missing data
     precip_fitted_df <- na.omit(precip_fitted_df)

     # Perform hierarchical clustering with k = 4
     set.seed(123)
     precip_matrix <- precip_fitted_df %>% dplyr::select(-iso_code)
     dist_matrix <- dist(precip_matrix)  # Compute distance matrix
     hc <- hclust(dist_matrix, method = clustering_method)
     precip_fitted_df$cluster <- cutree(hc, k = k)  # Assign countries to 4 clusters

     # Step 2: Merge clustering results with spatial data

     africa <- sf::st_read(dsn = file.path(PATHS$DATA_SHAPEFILES, "AFRICA_ADM0.shp"))

     africa_with_clusters <- africa %>%
          dplyr::left_join(precip_fitted_df %>% dplyr::select(iso_code, cluster), by = c("iso_a3" = "iso_code"))

     #africa_with_clusters <- africa_with_clusters[!(africa_with_clusters$iso_a3 %in% c("ZAF")),]

     # Step 3: Calculate centroids for all African countries
     centroids <- sf::st_centroid(africa)
     coords <- sf::st_coordinates(centroids)

     # Initial value of k for nearest neighbors
     initial_k <- 10

     # Step 4: Loop through countries with no cholera data and select the best neighbor

     for (country_iso_code_no_data in iso_codes_no_data) {

          print(glue("Processing country with no cholera data: {country_iso_code_no_data}"))

          # Get the shapefile for the country with no data
          country_shp_no_data <- sf::st_read(dsn = file.path(PATHS$DATA_SHAPEFILES, paste0(country_iso_code_no_data, "_ADM0.shp")))

          # Ensure both country_shp_no_data and africa have the same CRS
          country_shp_no_data <- sf::st_transform(country_shp_no_data, sf::st_crs(africa))

          # Get the centroid of the country with no data
          centroid_no_data <- sf::st_centroid(country_shp_no_data)
          coord_no_data <- sf::st_coordinates(centroid_no_data)

          # Get the cluster assignment for the country with no data
          country_cluster <- precip_fitted_df %>%
               dplyr::filter(iso_code == country_iso_code_no_data) %>%
               dplyr::pull(cluster)

          # Initialize variables for tracking the best neighbor
          best_neighbor_iso_code <- NULL
          highest_corr <- -Inf

          # Step 5: Check for neighbors within the same cluster
          neighbors_within_cluster <- africa_with_clusters %>%
               dplyr::filter(cluster == country_cluster, iso_a3 != country_iso_code_no_data, iso_a3 %in% iso_codes_with_data)

          if (nrow(neighbors_within_cluster) > 0) {

               print(glue("Found {nrow(neighbors_within_cluster)} neighbors within the same cluster for {country_iso_code_no_data}"))

               # Get the precipitation data for the country with no data
               precip_no_data <- all_precip_data[[country_iso_code_no_data]] %>%
                    dplyr::select(year, week, weekly_precipitation_sum)

               # Loop through neighbors within the cluster and find the best one based on correlation
               for (neighbor_iso_code in neighbors_within_cluster$iso_a3) {

                    precip_neighbor <- all_precip_data[[neighbor_iso_code]] %>%
                         dplyr::select(year, week, weekly_precipitation_sum)

                    # Merge data by year and week for correlation calculation
                    merged_precip <- merge(precip_no_data, precip_neighbor, by = c("year", "week"), suffixes = c("_no_data", "_neighbor"))

                    if (nrow(merged_precip) > 0) {

                         # Calculate Pearson correlation
                         corr <- cor(merged_precip$weekly_precipitation_sum_no_data, merged_precip$weekly_precipitation_sum_neighbor, use = "complete.obs")

                         print(glue("Correlation between {country_iso_code_no_data} and {neighbor_iso_code}: {corr}"))

                         # Update the best neighbor if this correlation is higher
                         if (corr > highest_corr) {
                              highest_corr <- corr
                              best_neighbor_iso_code <- neighbor_iso_code
                         }
                    }
               }

          }

          # Step 6: If no valid neighbor is found within the cluster, check k-nearest neighbors
          if (is.null(best_neighbor_iso_code)) {

               print(glue("No neighbors within the same cluster for {country_iso_code_no_data}. Checking nearest neighbors."))

               k <- initial_k

               while (is.null(best_neighbor_iso_code)) {

                    # Find k-nearest neighbors based on centroid distance
                    k_neighbors <- FNN::get.knnx(coords, coord_no_data, k = k)
                    nearest_neighbors <- africa[k_neighbors$nn.index, ]

                    # Filter neighbors to only include those that have cholera data
                    neighbors_with_data <- nearest_neighbors %>%
                         dplyr::filter(iso_a3 %in% iso_codes_with_data)

                    if (nrow(neighbors_with_data) == 0) {
                         print(glue("No neighbors with data found with k = {k}. Increasing k."))
                         k <- k + 1  # Increase k until a valid neighbor with data is found
                    }

                    # Stop if k exceeds the total number of available neighbors
                    if (k > nrow(africa)) {
                         print(glue("No valid neighbors found for {country_iso_code_no_data} even after increasing k. Skipping."))
                         next
                    }

                    # Get the precipitation data (weekly_precipitation_sum) for the country with no data
                    precip_no_data <- all_precip_data[[country_iso_code_no_data]] %>%
                         dplyr::select(year, week, weekly_precipitation_sum)

                    # Loop through k-nearest neighbors and calculate the correlation between weekly_precipitation_sum
                    for (neighbor_iso_code in neighbors_with_data$iso_a3) {

                         if (is.null(all_precip_data[[neighbor_iso_code]])) {
                              print(paste0("Cannot find neighbor iso code: ", neighbor_iso_code))
                              next
                         }

                         precip_neighbor <- all_precip_data[[neighbor_iso_code]] %>%
                              dplyr::select(year, week, weekly_precipitation_sum)

                         # Merge data by year and week for correlation calculation
                         merged_precip <- merge(precip_no_data, precip_neighbor, by = c("year", "week"), suffixes = c("_no_data", "_neighbor"))

                         if (nrow(merged_precip) > 0) {

                              # Calculate Pearson correlation
                              corr <- cor(merged_precip$weekly_precipitation_sum_no_data, merged_precip$weekly_precipitation_sum_neighbor, use = "complete.obs")

                              print(glue("Correlation between {country_iso_code_no_data} and {neighbor_iso_code}: {corr}"))

                              # Update the best neighbor if this correlation is higher and positive
                              if (corr > highest_corr) {
                                   highest_corr <- corr
                                   best_neighbor_iso_code <- neighbor_iso_code
                              }
                         }
                    }
               }
          }


          # Step 7: If a best neighbor is found, assign the fitted and parameter values
          if (!is.null(best_neighbor_iso_code)) {

               print(glue("Best neighbor based on correlation: {best_neighbor_iso_code} with correlation {highest_corr}"))

               combined_fitted_values[combined_fitted_values$iso_code == country_iso_code_no_data, 'fitted_values_fourier_cases'] <-
                    combined_fitted_values[combined_fitted_values$iso_code == best_neighbor_iso_code, 'fitted_values_fourier_cases']

               combined_fitted_values[combined_fitted_values$iso_code == country_iso_code_no_data, 'inferred_from_neighbor'] <- convert_iso_to_country(best_neighbor_iso_code)

               combined_param_values[combined_param_values$country_iso_code == country_iso_code_no_data & combined_param_values$response == 'cases', c('parameter', 'mean', 'se', 'ci_lo', 'ci_hi')] <-
                    combined_param_values[combined_param_values$country_iso_code == best_neighbor_iso_code & combined_param_values$response == 'cases', c('parameter', 'mean', 'se', 'ci_lo', 'ci_hi')]

               combined_param_values[combined_param_values$country_iso_code == country_iso_code_no_data & combined_param_values$response == 'cases', 'inferred_from_neighbor'] <- convert_iso_to_country(best_neighbor_iso_code)

               print(glue("Assigned data from {best_neighbor_iso_code} to {country_iso_code_no_data}"))

          } else {
               print(glue("No valid neighbor found with a positive correlation for {country_iso_code_no_data}."))
          }
     }


     message('Downscaling weekly seasonality to daily time steps...')

     convert_doy_to_woy <- function(day_of_year, year) {
          # Validate inputs
          if (any(day_of_year < 1 | day_of_year > 366)) {
               stop("day_of_year must be between 1 and 366.")
          }

          if (any(year < 0)) {
               stop("year must be a positive integer.")
          }

          # Convert day_of_year to ISO date
          dates <- as.Date(ISOdate(year, 1, 1)) + (day_of_year - 1)

          # Extract ISO week of year
          week_of_year <- as.integer(strftime(dates, format = "%V"))

          # Cap the week number at 52
          week_of_year <- pmin(week_of_year, 52)

          return(week_of_year)
     }

     convert_woy_to_moy <- function(weeks_of_year, year) {
          # Validate inputs
          if (any(weeks_of_year < 1 | weeks_of_year > 52)) {
               stop("weeks_of_year must be between 1 and 52.")
          }

          if (any(year < 0)) {
               stop("year must be a positive integer.")
          }

          # Convert weeks to approximate middle day of the week
          middle_days <- (weeks_of_year - 1) * 7 + 4  # Middle of the week (ISO weeks start on Monday)

          # Convert middle day of the week to an ISOdate
          dates <- as.Date(ISOdate(year, 1, 1)) + (middle_days - 1)

          # Extract the month from the ISOdate
          months_of_year <- as.integer(format(dates, "%m"))

          return(months_of_year)
     }



     # Seasonal patterns done on weekly time scale
     combined_fitted_values_weekly <- combined_fitted_values
     cols <- c('week', 'iso_code', 'Country', 'fitted_values_fourier_precip', 'fitted_values_fourier_cases', 'inferred_from_neighbor')
     combined_fitted_values_weekly <- combined_fitted_values_weekly[,cols]

     # Convert to day of year scale and smooth
     combined_fitted_values_daily <- expand.grid(list(day = 1:366, iso_code = unique(combined_fitted_values$iso_code)))
     combined_fitted_values_daily$week <- convert_doy_to_woy(combined_fitted_values_daily$day, 2024)
     combined_fitted_values_daily <- merge(combined_fitted_values_daily, combined_fitted_values_weekly, by=c('week', 'iso_code'))


     split_data <- split(combined_fitted_values_daily, combined_fitted_values_daily$iso_code)

     smoothed_list <- lapply(split_data, function(group) {

          message(group$iso_code[1])
          days <- seq(min(group$day), max(group$day), by = 1)

          smoothed_precip <- stats::predict(loess(fitted_values_fourier_precip ~ day, data = group, span = 0.1), newdata = days)
          smoothed_cases <- stats::predict(loess(fitted_values_fourier_cases ~ day, data = group, span = 0.1), newdata = days)

          data.frame(
               iso_code = unique(group$iso_code),
               day = days,
               fitted_values_fourier_precip = smoothed_precip,
               fitted_values_fourier_cases = smoothed_cases,
               Country = unique(group$Country),
               inferred_from_neighbor = unique(group$inferred_from_neighbor)
          )
     })

     combined_fitted_values_daily <- do.call(rbind, smoothed_list)
     cols <- c('day', 'iso_code', 'Country', 'fitted_values_fourier_precip', 'fitted_values_fourier_cases', 'inferred_from_neighbor')
     combined_fitted_values_daily <- combined_fitted_values_daily[,cols]


     # Convert to monthly scale and aggregate
     combined_fitted_values_monthly <- combined_fitted_values_weekly
     combined_fitted_values_monthly$month <- convert_woy_to_moy(combined_fitted_values_monthly$week, 2024)

     sel <- order(combined_fitted_values_monthly$iso_code, combined_fitted_values_monthly$month)
     combined_fitted_values_monthly <- combined_fitted_values_monthly[sel,]

     combined_fitted_values_monthly <-
          combined_fitted_values_monthly %>%
          group_by(iso_code, Country, inferred_from_neighbor, month) %>%
          mutate(fitted_values_fourier_precip = mean(fitted_values_fourier_precip, na.rm = TRUE),
                 fitted_values_fourier_cases = mean(fitted_values_fourier_cases, na.rm = TRUE)) %>%
          distinct() %>%
          as.data.frame()

     combined_fitted_values_monthly <- combined_fitted_values_monthly[,-1]

     cols <- c('month', 'iso_code', 'Country', 'fitted_values_fourier_precip', 'fitted_values_fourier_cases', 'inferred_from_neighbor')
     combined_fitted_values_monthly <- combined_fitted_values_monthly[,cols]


     # Save the outputs to CSV files
     utils::write.csv(combined_fitted_values_daily, file.path(PATHS$MODEL_INPUT, "pred_seasonal_dynamics_day.csv"), row.names = FALSE)
     utils::write.csv(combined_fitted_values_weekly, file.path(PATHS$MODEL_INPUT, "pred_seasonal_dynamics_week.csv"), row.names = FALSE)
     utils::write.csv(combined_fitted_values_monthly, file.path(PATHS$MODEL_INPUT, "pred_seasonal_dynamics_month.csv"), row.names = FALSE)
     message(glue("Daily, weekly, and monthly seasonal outputs saved to {PATHS$MODEL_INPUT}"))

     path1 <- file.path(PATHS$MODEL_INPUT, "data_seasonal_precipitation.csv")
     path2 <- file.path(PATHS$DOCS_TABLES, "data_seasonal_precipitation.csv")
     utils::write.csv(combined_precip_data, file = path1, row.names = FALSE)
     utils::write.csv(combined_precip_data, file = path2, row.names = FALSE)
     message("Weekly precipitation data saved to:")
     message(path1)
     message(path2)

     path1 <- file.path(PATHS$MODEL_INPUT, "param_seasonal_dynamics.csv")
     path2 <- file.path(PATHS$DOCS_TABLES, "param_seasonal_dynamics.csv")
     utils::write.csv(combined_param_values, file = path1, row.names = FALSE)
     utils::write.csv(combined_param_values, file = path2, row.names = FALSE)
     message("Estimated fourier series parameters saved to: ")
     message(path1)
     message(path2)



}
