#' Process Environmental Suitability Data for Cholera Transmission
#'
#' This function loads climate data, ENSO data, and weekly cholera cases data, processes them, and merges them into a dataset to estimate the environmental suitability for cholera transmission based on various environmental factors.
#'
#' @param PATHS A list containing paths where the data is stored. Typically generated by the `get_paths()` function and should include:
#' \itemize{
#'   \item \strong{DATA_CLIMATE}: Path to the directory where processed climate data is stored.
#'   \item \strong{DATA_ENSO}: Path to the directory where ENSO data is stored.
#'   \item \strong{DATA_WHO_WEEKLY}: Path to the directory containing processed weekly cholera cases data.
#' }
#'
#' @return This function processes the data and merges the climate, ENSO, and cholera cases data into a single dataset. The processed dataset is saved as a CSV file.
#'
#' @importFrom arrow read_parquet
#' @importFrom utils read.csv write.csv
#' @importFrom glue glue
#' @importFrom dplyr left_join select_if select
#' @importFrom tidyr pivot_wider
#' @export
process_suitability_data <- function(PATHS) {

     requireNamespace('arrow')
     requireNamespace('ISOweek')
     requireNamespace('dplyr')
     requireNamespace('tidyr')

     # Load climate data for all countries (weekly)
     message("Loading climate data...")

     # List all weekly climate data files
     climate_files <- list.files(PATHS$DATA_CLIMATE, pattern = "weekly\\.parquet$", full.names = TRUE)

     # Initialize an empty list to store climate data for each ISO code
     climate_data_list <- list()

     # Loop through each climate file and load the data
     for (climate_file in climate_files) {
          climate_data <- arrow::read_parquet(climate_file)
          climate_data_list <- append(climate_data_list, list(climate_data))
     }

     # Combine all climate data into one data frame
     combined_climate_data <- do.call(rbind, climate_data_list)
     rm(climate_data_list)

     # Load ENSO data (compiled ENSO and DMI data)
     message("Loading ENSO and DMI data...")
     enso_file <- file.path(PATHS$DATA_ENSO, "compiled_ENSO_1970_2025_weekly.csv")
     enso_data <- utils::read.csv(enso_file, stringsAsFactors = FALSE)

     # Load weekly cholera cases data
     message("Loading weekly cholera cases data...")
     cases_file <- file.path(PATHS$DATA_WHO_WEEKLY, "cholera_country_weekly_processed.csv")
     cases_data <- utils::read.csv(cases_file, stringsAsFactors = FALSE)

     message("Merging datasets...")
     # Convert the climate data to wide format, with variable names as new columns
     combined_climate_data_wide <- tidyr::pivot_wider(
          combined_climate_data,
          names_from = variable_name,
          values_from = value
     )

     combined_climate_data_wide <- combined_climate_data_wide %>%
          dplyr::select(-date_start, -date_stop)

     # Convert ENSO data to wide format (DMI, ENSO3, ENSO34, ENSO4 as new columns)
     enso_data_wide <- tidyr::pivot_wider(
          enso_data,
          names_from = variable,
          values_from = value
     )

     enso_data_wide <- enso_data_wide %>%
          dplyr::select(-date_start, -date_stop)

     # Merge datasets: Merge cases data with wide climate data and ENSO data
     combined_climate_data_wide <- merge(combined_climate_data_wide, enso_data_wide, by = c("year", "week"), all.x = TRUE)
     d <- merge(cases_data, combined_climate_data_wide, by = c("iso_code", "year", "week"), all.y = TRUE)

     # Convert ISO code to country names
     d$country <- MOSAIC::convert_iso_to_country(d$iso_code)

     # Limit week values to 1-52
     d <- d %>%
          filter(week >= 1 & week <= 52)

     # Create ISO week strings
     d$iso_week <- paste0(d$year, "-W", sprintf("%02d", d$week))

     # Convert ISO week to date_start (Monday) and date_stop (Sunday)
     d$date_start <- ISOweek::ISOweek2date(paste0(d$iso_week, "-1"))
     d$date_stop <- ISOweek::ISOweek2date(paste0(d$iso_week, "-7"))

     # Remove the temporary iso_week column
     d$iso_week <- NULL

     # Remove columns that are entirely NA or NaN
     d <- dplyr::select_if(d, ~!all(is.na(.) | is.nan(.)))

     if ("rain_sum" %in% colnames(d)) d <- d[,-which(colnames(d) == 'rain_sum')]

     # Remove unnecessary objects from memory
     rm(cases_data, combined_climate_data, combined_climate_data_wide, enso_data, enso_data_wide)

     if (53 %in% d$week) stop("week index is out of bounds")

     # Save the merged dataset to a CSV file
     path <- file.path(PATHS$DATA_WHO_WEEKLY, 'cholera_country_weekly_suitability_data.csv')
     write.csv(d, file = path, row.names = FALSE)
     message("Processed suitability data saved here: ", path)
}
