% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/npe_funcs.R
\name{plot_npe_training_loss}
\alias{plot_npe_training_loss}
\title{Plot NPE Training Loss Curves}
\usage{
plot_npe_training_loss(
  npe_model_dir,
  output_file = NULL,
  plot_width = 10,
  plot_height = 6,
  show_individual_ensembles = TRUE,
  smooth_curves = TRUE,
  verbose = TRUE
)
}
\arguments{
\item{npe_model_dir}{Directory containing trained NPE model with training_history.json}

\item{output_file}{Optional path to save the plot (default: NULL for display only)}

\item{plot_width}{Plot width in inches (default: 10)}

\item{plot_height}{Plot height in inches (default: 6)}

\item{show_individual_ensembles}{Logical; show individual ensemble curves (default: TRUE)}

\item{smooth_curves}{Logical; apply smoothing to loss curves (default: TRUE)}

\item{verbose}{Logical; print progress messages (default: TRUE)}
}
\value{
ggplot2 object containing the training loss visualization
}
\description{
Creates training and validation loss curves for NPE models, showing convergence
behavior and potential overfitting. Supports ensemble models by plotting
individual curves and ensemble statistics.
}
\details{
This function loads the training history from training_history.json and creates
publication-quality plots showing:
\enumerate{
\item Training and validation loss curves over epochs
\item Individual ensemble member curves (if multiple ensembles)
\item Ensemble mean and confidence intervals
\item Best validation loss points
\item Training convergence diagnostics
}

The plot helps identify:
\itemize{
\item Training convergence
\item Overfitting (validation loss increasing while training loss decreases)
\item Ensemble consistency
\item Optimal stopping points
}
}
\examples{
\dontrun{
# Plot training curves for NPE model
loss_plot <- plot_npe_training_loss(
  npe_model_dir = "./results/npe",
  output_file = "./figures/npe_training_loss.png"
)

# Display the plot
print(loss_plot)
}

}
