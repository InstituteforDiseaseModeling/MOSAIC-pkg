% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/npe.R
\name{prepare_npe_data}
\alias{prepare_npe_data}
\title{Prepare NPE Training Data from BFRS Results}
\usage{
prepare_npe_data(
  bfrs_dir,
  results = NULL,
  param_names = NULL,
  verbose = TRUE,
  chunk_size = NULL
)
}
\arguments{
\item{bfrs_dir}{Directory containing BFRS results with:
\itemize{
\item simulations.parquet: Parameter values and weights
\item outputs/timeseries/timeseries_NNNNNNN.parquet: Individual timeseries files
\item priors.json: Parameter prior distributions
}}

\item{results}{Optional data frame of BFRS results already loaded in memory
(NULL = load from file). Preferred when results are already available to
avoid redundant file I/O. Must contain columns: sim, likelihood, and parameter columns.}

\item{param_names}{Character vector of parameter names to extract (NULL = auto-detect)}

\item{verbose}{Logical, print progress messages (default: TRUE)}

\item{chunk_size}{Integer, chunk size for processing large datasets (NULL = auto)}
}
\value{
List containing:
\describe{
\item{parameters}{Matrix of parameter values (n_sims × n_params)}
\item{observations}{Matrix of flattened time series (n_sims × n_features)}
\item{weights}{Vector of simulation weights}
\item{bounds}{Matrix of parameter bounds (n_params × 2)}
\item{param_names}{Character vector of parameter names}
\item{n_samples, n_params, n_timesteps, n_locations}{Integer dimensions}
\item{observed_data}{Optional data frame of observed data (if available)}
}
}
\description{
Loads simulation outputs and parameters from BFRS results directory and prepares
them for Neural Posterior Estimation (NPE) training. Optimized to load only
individual output files for weighted simulations, avoiding the need to read
and filter a large combined outputs file.
}
\details{
This function implements a high-performance loading strategy:
\enumerate{
\item Loads simulations.parquet to identify weighted simulations
\item Loads only the individual timeseries files for weighted simulations
\item Combines loaded files using data.table::rbindlist() for efficiency
\item Reshapes data from long to wide format for NPE training
}

Performance: For typical BFRS results with 1\\% weighted simulations:
\itemize{
\item Old approach (combined file): 30-120 seconds to load and filter 45M rows
\item New approach (individual files): 0.1-0.5 seconds to load 450K rows directly
\item Speedup: 100-1200× faster
}

The function expects individual output files in the outputs/timeseries/ subdirectory.
These files are created during simulation. The entire outputs/ directory can be
removed after NPE training completes to free disk space.
}
\examples{
\dontrun{
# Basic usage (loads from file)
npe_data <- prepare_npe_data(
    bfrs_dir = "path/to/1_bfrs",
    param_names = c("beta_env", "beta_hum", "tau_i")
)

# Optimized usage (pass pre-loaded results)
results <- arrow::read_parquet("path/to/1_bfrs/outputs/simulations.parquet")
results$weight_npe <- get_npe_weights(results, strategy = "continuous_best")
npe_data <- prepare_npe_data(
    bfrs_dir = "path/to/1_bfrs",
    results = results,
    param_names = c("beta_env", "beta_hum", "tau_i")
)
}
}
