% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/npe_funcs.R
\name{train_npe}
\alias{train_npe}
\title{Train Neural Posterior Estimator for MOSAIC Parameters}
\usage{
train_npe(
  simulations_file,
  outputs_file,
  output_dir,
  param_names = NULL,
  simulation_filter = "complete_cases",
  architecture = "auto",
  override_spec = NULL,
  use_gpu = TRUE,
  seed = 42,
  verbose = TRUE
)
}
\arguments{
\item{simulations_file}{Character string path to simulations parquet file containing
parameter samples and metadata from MOSAIC calibration runs. Expected columns include
parameter names, \code{likelihood}, and quality indicators like \code{is_finite}.}

\item{outputs_file}{Character string path to outputs parquet file containing time series
results from MOSAIC simulations. Expected columns: \code{sim}, \code{iter}, \code{j}
(location), \code{t} (time), \code{cases}, \code{deaths}.}

\item{output_dir}{Character string path where trained NPE models will be saved.
Will create directory if it doesn't exist.}

\item{param_names}{Character vector of parameter names to include in training.
If NULL (default), automatically detects parameters from simulation results.}

\item{simulation_filter}{Character vector specifying quality filters to apply:
\itemize{
\item \code{"all"} — Use all simulations (no filtering)
\item \code{"complete_cases"} — Remove simulations with missing values
\item \code{"is_finite"} — Keep only simulations with finite likelihoods
\item \code{"is_retained"} — Use convergence-retained simulations only
}}

\item{architecture}{Character string specifying NPE architecture:
\itemize{
\item \code{"auto"} — Automatically select based on data characteristics (default)
\item \code{"tiny", "small", "medium", "large", "xlarge"} — Predefined sizes
\item Custom preset names: \code{"epidemic_small", "epidemic_large", "endemic"}
}}

\item{override_spec}{Named list of architecture overrides. See \code{\link{calc_npe_spec}}
for available options.}

\item{use_gpu}{Logical indicating whether to attempt GPU acceleration if available.
Default is TRUE.}

\item{seed}{Integer random seed for reproducible training. Default is 42.}

\item{verbose}{Logical indicating whether to print progress messages. Default is TRUE.}
}
\value{
Named list containing:
\itemize{
\item \code{output_dir} — Path to saved model directory
\item \code{spec} — NPE architecture specification used
\item \code{param_names} — Parameter names included in training
\item \code{n_simulations} — Number of simulations used for training
\item \code{training_time} — Time taken for training
}
}
\description{
Trains a Neural Posterior Estimator (NPE) using the Lampe library to approximate
posterior distributions for MOSAIC cholera model parameters. This function processes
MOSAIC calibration results to create a fast surrogate for Bayesian inference.
}
\details{
This function implements Neural Posterior Estimation using the Lampe library,
which provides efficient simulation-based inference for complex models. The NPE
learns to approximate \eqn{p(\theta|x)} directly from simulation pairs \eqn{(\theta, x)}.

The training process includes:
\itemize{
\item Data preprocessing and parameter bounds extraction via \code{\link{.get_npe_prior_bounds}}
\item Architecture specification via \code{\link{calc_npe_spec}}
\item Neural network training using normalizing flows
\item Model ensemble creation for uncertainty quantification
}
}
\section{External Dependencies}{

This function requires:
\itemize{
\item \strong{Lampe}: Neural posterior estimation library (\url{https://github.com/probabilists/lampe})
\item \strong{PyTorch}: Deep learning framework (\url{https://pytorch.org/})
\item \strong{Python}: Compatible environment managed via reticulate
}
}

\examples{
\dontrun{
# Train NPE model from MOSAIC calibration results
npe_model <- train_npe(
  simulations_file = "path/to/simulations.parquet",
  outputs_file = "path/to/outputs.parquet",
  output_dir = "path/to/npe/models",
  simulation_filter = c("is_finite", "is_retained"),
  architecture = "auto",
  use_gpu = TRUE,
  seed = 123
)
}

}
\references{
\itemize{
\item Rozet, F. & Louppe, G. (2021). "Lampe: Likelihood-free AMortized Posterior Estimation."
\item Papamakarios, G., et al. (2019). "Sequential Neural Likelihood." \emph{AISTATS}.
}
}
\seealso{
\itemize{
\item \code{\link{est_npe_posterior}} for parameter estimation using trained models
\item \code{\link{calc_npe_spec}} for architecture specification details
\item \code{\link{sample_from_prior_batch}} for prior sampling utilities
}
}
